{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "links = pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging links to movies to use IMDb IDs (For web-scrapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "movies = movies.merge(links, on='movieId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping movie description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_movie_description(imdb_id):\n",
    "    url = f\"https://www.imdb.com/title/tt{imdb_id}/\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            description_tag = soup.find('div', attrs={'class': 'summary_text'})\n",
    "            return description_tag.text.strip() if description_tag else 'No description available'\n",
    "    except:\n",
    "        return 'No description available'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "movies['description'] = movies['imdbId'].apply(scrape_movie_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_glove_embeddings(path):\n",
    "    embeddings_dict = {}\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_dict[word] = vector\n",
    "    return embeddings_dict\n",
    "\n",
    "glove_path = 'glove.6B.100d.txt'\n",
    "glove_embeddings = load_glove_embeddings(glove_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert descriptions to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def description_to_embedding(description):\n",
    "    words = description.lower().split()\n",
    "    embeddings = [glove_embeddings[word] for word in words if word in glove_embeddings]\n",
    "    if embeddings:\n",
    "        embeddings = torch.tensor(embeddings)\n",
    "        return torch.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return torch.zeros(100, dtype=torch.float32)\n",
    "\n",
    "movies['embedding'] = movies['description'].apply(description_to_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity matrix for CBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_matrix = torch.stack(movies['embedding'].tolist()).numpy()\n",
    "item_similarity = cosine_similarity(embeddings_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity matrix for CF (User-Item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "user_item_matrix = ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "user_similarity = cosine_similarity(user_item_matrix.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get CF & CBF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_cf_scores(user_id, user_similarity_matrix, user_item_matrix):\n",
    "    sim_scores = user_similarity_matrix[user_id - 1]\n",
    "    weighted_scores = np.dot(sim_scores, user_item_matrix)\n",
    "    sim_scores_sum = np.array([np.abs(sim_scores).sum(axis=0)])\n",
    "    return weighted_scores / sim_scores_sum\n",
    "\n",
    "def get_cbf_scores(user_id, item_similarity_matrix, user_item_matrix):\n",
    "    user_ratings = user_item_matrix.iloc[user_id - 1]\n",
    "    weighted_scores = np.dot(item_similarity_matrix, user_ratings.T)\n",
    "    return weighted_scores / np.sum(item_similarity_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using XGBoost to combine the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_recommendations(user_id, top_n=10):\n",
    "    cf_scores = get_cf_scores(user_id, user_similarity, user_item_matrix)\n",
    "    cbf_scores = get_cbf_scores(user_id, item_similarity, user_item_matrix)\n",
    "    features = np.vstack((cf_scores, cbf_scores)).T\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, ratings['rating'], test_size=0.2, random_state=42)\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    recommended_movie_ids = np.argsort(predictions)[::-1][:top_n]\n",
    "    recommended_movies = movies.loc[movies['movieId'].isin(recommended_movie_ids)]\n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations for a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    user_id = int(input(\"Enter the User ID for which you want recommendations: \"))\n",
    "    \n",
    "    if user_id not in user_item_matrix.index:\n",
    "        print(f\"User ID {user_id} does not exist in the dataset. Please try again.\")\n",
    "    else:\n",
    "        recommendations = get_recommendations(user_id, w_cf=0.5, w_cbf=0.5, top_n=10)\n",
    "        \n",
    "        # Display the recommendations\n",
    "        print(f\"\\nTop recommended movies for you, {user_id}:\")\n",
    "        print(recommendations)\n",
    "except ValueError:\n",
    "    print(\"Invalid input. Please enter a numeric User ID.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
